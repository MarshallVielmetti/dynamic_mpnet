"""
@file summarize_data.py
@brief Summarizes the data generated by rrt_data_gen using the metadata
"""

import json
import numpy as np

import os


import argparse

parser = argparse.ArgumentParser("summarize_data")
parser.add_argument(
    "--data-dir",
    type=str,
    default="code/data",
    help="Directory where the data is stored",
)


def main():
    """
    Main function to summarize the data
    """

    args = parser.parse_args()
    data_dir = args.data_dir

    # Check if the data directory exists
    if not os.path.exists(data_dir):
        print(f"Data directory {data_dir} does not exist.")
        return

    # If it already exists, remove the current metadata file
    top_metadata_path = os.path.join(data_dir, "metadata.json")
    if os.path.exists(top_metadata_path):
        os.remove(top_metadata_path)

    # Get a list of the subdirectories
    subdirs = [
        os.path.join(data_dir, d)
        for d in os.listdir(data_dir)
        if os.path.isdir(os.path.join(data_dir, d))
    ]

    top_metadata = {}

    # Print the subdirectories
    print(f"Analyzing Metadata from {len(subdirs)} runs.")

    num_valid_maps = 0
    num_valid_trajectories = 0

    delete_dirs = []

    for subdir in subdirs:
        meta_path = os.path.join(subdir, "metadata.json")

        subdir_id = subdir.split("/")[-1]
        print(f"Analyzing {subdir_id}...")

        # Check if the metadata file exists
        if not os.path.exists(meta_path):
            print(f"Metadata file {meta_path} does not exist.")
            delete_dirs.append(subdir)
            continue

        # Load the metadata
        with open(meta_path, "r") as f:
            metadata = json.load(f)

            # Check if the metadata is valid
            if "map_metadata" not in metadata:
                print(f"Invalid metadata file {meta_path}.")
                continue

            # Get the size of the map
            size = metadata["map_size"]
            if size not in top_metadata:
                top_metadata[size] = {"dirs": [], "num_maps": 0, "num_trajectories": 0}

            # Add this directory to the metadata for maps this size
            top_metadata[size]["dirs"].append(subdir)
            top_metadata[size]["num_maps"] += len(metadata["map_metadata"])
            top_metadata[size]["num_trajectories"] += sum(
                [meta["num_trajectories"] for meta in metadata["map_metadata"]]
            )

    # Write the top level metadata
    with open(top_metadata_path, "w") as f:
        json.dump(top_metadata, f, indent=4)

    print(f"\n\n ###### SUMMARY ######")
    print(f"Total number of runs: {len(subdirs)}")
    print(f"Found maps generated of sizes: {list(top_metadata.keys())}")

    for size, meta in top_metadata.items():
        print(f"\nSize: {size}")
        print(f"\t Number of maps: {meta['num_maps']}")
        print(f"\t Number of trajectories: {meta['num_trajectories']}")
        print(f"\t Directories: {meta['dirs']}")

    print(
        f"\n\n To delete failed directories, run:\n sudo rm -rf {[' '.join(dir) for dir in delete_dirs]}"
    )


if __name__ == "__main__":
    main()
